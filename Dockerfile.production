# PRODUCTION AWS Lambda Dockerfile - HTTP SCRAPING SOLUTION (No Browser Required)
FROM public.ecr.aws/lambda/python:3.11

# Install minimal system dependencies (no browser needed)
RUN yum update -y && \
    yum install -y \
    curl \
    wget \
    && yum clean all

# Set environment variables for HTTP scraping approach
ENV SCRAPING_APPROACH=http_requests
ENV PYTHONPATH=/opt/python:/var/task
ENV ENVIRONMENT=lambda

# Create required directories
RUN mkdir -p /tmp/pdfs /var/task && \
    chmod -R 777 /tmp

# Copy requirements first for better Docker layer caching
COPY requirements-lambda.txt .

# Install Python dependencies to Lambda layer directory
RUN pip install --no-cache-dir --target /opt/python -r requirements-lambda.txt

# Copy application code to Lambda task directory
COPY server.py competitive_exam_keywords.py health_check.py ./
COPY lambda_handler_production.py ./
COPY s3_production_integration.py ./

# Set proper executable permissions  
RUN chmod +x lambda_handler_production.py

# Create verification script
RUN echo '#!/bin/bash\n\
echo "=== HTTP Scraping Solution Verification ==="\n\
python3 -c "import requests; print(f\"Requests: {requests.__version__}\")"\n\
python3 -c "import beautifulsoup4; print(\"BeautifulSoup: Available\")"\n\
echo "=== Verification Complete ==="' > /opt/verify_http.sh && \
    chmod +x /opt/verify_http.sh

# Run verification during build
RUN /opt/verify_http.sh

# Set the Lambda handler
CMD ["lambda_handler_production.handler"]