# PRODUCTION AWS Lambda Dockerfile - HTTP SCRAPING SOLUTION (No Browser Required)
FROM public.ecr.aws/lambda/python:3.11

# Install minimal system dependencies (no browser needed)
RUN yum update -y && \
    yum install -y \
    curl \
    wget \
    && yum clean all

# Set environment variables for HTTP scraping approach
ENV SCRAPING_APPROACH=http_requests
ENV PYTHONPATH=/opt/python:/var/task
ENV ENVIRONMENT=lambda

# Create required directories
RUN mkdir -p /tmp/pdfs /var/task && \
    chmod -R 777 /tmp

# Copy requirements first for better Docker layer caching
COPY requirements-lambda.txt .

# Install Python dependencies to Lambda layer directory
RUN pip install --no-cache-dir --target /opt/python -r requirements-lambda.txt

# Copy application code to Lambda task directory
COPY server.py competitive_exam_keywords.py health_check.py ./
COPY lambda_handler_production.py ./
COPY s3_production_integration.py ./

# Set proper executable permissions  
RUN chmod +x lambda_handler_production.py

# Create and run verification directly (fixed script issue)
RUN echo "=== HTTP Scraping Solution Verification ===" && \
    python3 -c "import requests; print('Requests:', requests.__version__)" && \
    python3 -c "from bs4 import BeautifulSoup; print('BeautifulSoup: Available')" && \
    echo "=== Verification Complete ==="

# Set the Lambda handler
CMD ["lambda_handler_production.handler"]